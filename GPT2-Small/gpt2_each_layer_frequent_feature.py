# -*- coding: utf-8 -*-
"""GPT2 each Layer Frequent Feature.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zUBv2T_mZvISPj-D_5ooeYgaIGPXyEvN
"""

!pip install sae-lens transformer_lens transformers datasets torch matplotlib scikit-learn

import torch
from tqdm import tqdm
from datasets import load_dataset
from sae_lens import SAE, HookedSAETransformer

device = "cuda" if torch.cuda.is_available() else "cpu"

model = HookedSAETransformer.from_pretrained("gpt2-small", device=device)

dataset = load_dataset("glue", "sst2", split="validation[:500]")  # subset for speed
texts = dataset["sentence"]

batch_size = 8
max_len = 64

# Layers to analyze (example: 12 transformer blocks)
layers_to_analyze = [f"blocks.{i}.hook_resid_pre" for i in range(12)]

top_features_per_layer = {}

for layer_name in layers_to_analyze:
    print(f"\nAnalyzing layer: {layer_name}")
    sae = SAE.from_pretrained(
        release="gpt2-small-res-jb",
        sae_id=layer_name,
        device=device,
    )

    feature_counts = torch.zeros(sae.cfg.d_sae, device=device)

    print("Counting feature frequencies...")
    for i in tqdm(range(0, len(texts), batch_size)):
        batch_texts = texts[i : i + batch_size]
        tokens = model.to_tokens(batch_texts)[:, :max_len].to(device)

        _, cache = model.run_with_cache(tokens, names_filter=[sae.cfg.metadata.hook_name])
        sae_in = cache[sae.cfg.metadata.hook_name]

        feature_acts = sae.encode(sae_in).squeeze()  # (batch, seq, d_sae)
        feature_counts += (feature_acts > 0).sum(dim=(0, 1))

    # Get top 10 frequent features as list of indices
    top_features = torch.topk(feature_counts, 10).indices.tolist()
    top_features_per_layer[layer_name] = top_features
    print(f"Top 10 most frequent features at {layer_name}: {top_features}")

# Now top_features_per_layer contains a list of top 10 feature IDs for each layer key
print("\nSummary of top features per layer:")
for layer, features in top_features_per_layer.items():
    print(f"{layer}: {features}")