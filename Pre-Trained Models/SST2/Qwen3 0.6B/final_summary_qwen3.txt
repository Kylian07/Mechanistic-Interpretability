======================================================================
FINAL SUMMARY - LAYER-WISE ANALYSIS (Qwen3 + Transcoders)
======================================================================

1. BASELINE (Zero-Shot Prompting)
----------------------------------------------------------------------
Accuracy: 88.30%
F1-Score: 0.8756

2. LAYER-WISE PERFORMANCE & SAE FEATURE STATISTICS
----------------------------------------------------------------------
Layer  Acc%     Improv     Pos Feat   Neg Feat   Common    
------------------------------------------------------------------------------------------
L0     75.46%   -12.84%    163838     163837     163837    
L1     75.69%   -12.61%    162009     162019     161750    
L2     75.57%   -12.73%    163824     163822     163820    
L3     75.11%   -13.19%    162158     162036     161538    
L4     78.10%   -10.21%    161167     161299     160208    
L5     79.01%    -9.29%    163685     163696     163615    
L6     80.50%    -7.80%    163175     163148     162995    
L7     80.85%    -7.45%    160545     160473     159328    
L8     81.42%    -6.88%    117524     116051     106449    
L9     81.88%    -6.42%    149810     148717     145130    
L10    84.06%    -4.24%    160866     160809     159631    
L11    84.86%    -3.44%    146131     145080     139285    
L12    86.01%    -2.29%    127349     125977     118273    
L13    84.98%    -3.33%    163603     163592     163473    
L14    85.55%    -2.75%    163787     163778     163753    
L15    85.32%    -2.98%    163696     163662     163589    
L16    84.86%    -3.44%    163734     163726     163662    
L17    84.75%    -3.56%    163818     163816     163803    
L18    85.09%    -3.21%    152651     152011     148496    
L19    81.19%    -7.11%    163580     163567     163414    
L20    82.11%    -6.19%    163832     163831     163828    
L21    80.28%    -8.03%    162713     162580     162141    
L22    79.13%    -9.17%    163541     163550     163382    
L23    78.56%    -9.75%    163325     163299     163119    
L24    76.38%   -11.93%    131847     128963     120345    
L25    78.21%   -10.09%    163316     163318     163094    
L26    75.57%   -12.73%    40216      37298      25125     
L27    76.03%   -12.27%    163798     163786     163768    

3. KEY FINDINGS
----------------------------------------------------------------------
Best Performing Layer: Layer 12
  Accuracy: 86.01%
  Improvement over baseline: -2.29%

Worst Performing Layer: Layer 3
  Accuracy: 75.11%

INTERPRETATION:
- Higher accuracy = more sentiment information in that layer
- Many pos-only / neg-only SAE features = stronger class separation
- Overlap among top-k frequent features quantifies common concepts
