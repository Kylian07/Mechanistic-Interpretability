# -*- coding: utf-8 -*-
"""Qwen3-0.6B model_MRPC

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/rajdeeppal2/qwen3-0-6b-model-mrpc.e5bcb2a5-0daa-4889-b00c-9a9351faa31c.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20260101/auto/storage/goog4_request%26X-Goog-Date%3D20260101T210137Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D876160ca3cf3e79c4a42d841c059936716f39c88cf520aa7550104338082ac5c45c441c5203410d258b0494184cd1365cd07c4444db9fddc4828ee0421dd33be430003cbc557713cc06530146ed397438ea61907951846b0735cdd0cdcd7e7866c48696778e49d1eba7edd23635244f314173469b53c3429c5fd6e33d9b4c747d09cf0a8da2f5315e7893d15ff2c2b9fc7924a2bc7f948fe008962f00f03456bb33922e05f22acf2794ef010b105ca53de6ef7764f7edcbebb504668323f101043bc99eb7fb75565213b54fac9b469bbb037a0304d3599a9ac5065c8104bbf369a12c1e31549b414740600f12758d4f6c9523cf3e5ddb9f3fbd7ddefd8d24c4f
"""

# -*- coding: utf-8 -*-

!pip install sae-lens
!pip install groq

# ================================================================
# 0. Auth & imports
# ================================================================
from kaggle_secrets import UserSecretsClient

import os
import gc
import torch
from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer
from sae_lens import SAE
from tqdm import tqdm
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import numpy as np
from collections import Counter
from huggingface_hub import login

# ------------------------------------------------
# Authenticate to Hugging Face using Kaggle secret
# ------------------------------------------------
user_secrets = UserSecretsClient()
hf_token = user_secrets.get_secret("HF_TOKEN")
if hf_token is None:
    raise ValueError("HF_TOKEN secret not found in Kaggle. Please add it in Add-ons > Secrets.")

os.environ["HF_TOKEN"] = hf_token
login(token=hf_token)

# ================================================================
# 1. Setup
# ================================================================
os.makedirs('/kaggle/working/hf_cache', exist_ok=True)
os.makedirs('/kaggle/working/results_mrpc_qwen3', exist_ok=True)

os.environ['HF_HOME'] = '/kaggle/working/hf_cache'
os.environ['TRANSFORMERS_CACHE'] = '/kaggle/working/hf_cache'
os.environ['HF_DATASETS_CACHE'] = '/kaggle/working/hf_cache'

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# ================================================================
# 2. Load Qwen3-0.6B-Base and MRPC
# ================================================================
base_model_id = "Qwen/Qwen3-0.6B-Base"
print(f"Loading model: {base_model_id} ...")

tokenizer = AutoTokenizer.from_pretrained(base_model_id)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    base_model_id,
    torch_dtype=torch.bfloat16,
    device_map=device,
)
model.eval()

n_layers = model.config.num_hidden_layers
print(f"Model has {n_layers} layers (0-{n_layers-1})")

print("Loading MRPC dataset...")
dataset = load_dataset("glue", "mrpc")
train_dataset = dataset["train"]
val_dataset = dataset["validation"]

print(f"Original sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}")

# Subsample train for speed (optional - adjust as needed)
train_dataset = train_dataset.select(range(min(2000, len(train_dataset))))

print(f"Train samples (subsampled): {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")

def combine_sentences(example):
    return f"{example['sentence1']} <|endoftext|> {example['sentence2']}"

# ================================================================
# Helper: get layer representation
# ================================================================
def get_layer_rep(text, layer_idx):
    enc = tokenizer(
        text,
        return_tensors="pt",
        padding=False,
        truncation=True,
        max_length=128,
    ).to(device)

    with torch.no_grad():
        out = model(
            **enc,
            output_hidden_states=True,
            use_cache=False,
        )

    hidden_states = out.hidden_states  # len = n_layers+1
    layer_h = hidden_states[layer_idx + 1]  # (1, seq, d_model)
    return layer_h

# ================================================================
# 3. STEP 1: Baseline - Zero-Shot Prompting
# ================================================================
print("\n" + "="*70)
print("STEP 1: BASELINE - ZERO-SHOT PROMPTING (Qwen3-0.6B on MRPC)")
print("="*70)

baseline_predictions = []
baseline_labels = []

with torch.no_grad():
    for idx in tqdm(range(len(val_dataset)), desc="Zero-Shot Evaluation"):
        s1 = val_dataset[idx]["sentence1"]
        s2 = val_dataset[idx]["sentence2"]
        true_label = val_dataset[idx]["label"]

        prompt = f"""Are these two sentences paraphrases?

Sentence 1: {s1}
Sentence 2: {s2}
Answer (yes/no):"""

        enc = tokenizer(
            prompt,
            return_tensors="pt",
            padding=False,
            truncation=True,
            max_length=256,
        ).to(device)

        out = model(**enc)
        logits = out.logits  # (1, seq, vocab)
        next_token_logits = logits[0, -1, :]
        next_token_id = torch.argmax(next_token_logits).item()
        generated_text = tokenizer.decode([next_token_id]).strip().lower()

        if "yes" in generated_text or generated_text.startswith("y"):
            prediction = 1
        elif "no" in generated_text or generated_text.startswith("n"):
            prediction = 0
        else:
            yes_id = tokenizer.encode(" yes")[-1]
            no_id = tokenizer.encode(" no")[-1]
            if next_token_logits[yes_id] > next_token_logits[no_id]:
                prediction = 1
            else:
                prediction = 0

        baseline_predictions.append(prediction)
        baseline_labels.append(true_label)

baseline_predictions = np.array(baseline_predictions)
baseline_labels = np.array(baseline_labels)

baseline_acc = accuracy_score(baseline_labels, baseline_predictions)
baseline_p, baseline_r, baseline_f1, _ = precision_recall_fscore_support(
    baseline_labels, baseline_predictions, average='binary'
)

print(f"\nBaseline Accuracy: {baseline_acc:.4f} ({baseline_acc*100:.2f}%)")
print(f"F1-Score: {baseline_f1:.4f}")

with open('/kaggle/working/results_mrpc_qwen3/baseline_results.txt', 'w') as f:
    f.write("="*70 + "\n")
    f.write("BASELINE - ZERO-SHOT PROMPTING (Qwen3-0.6B on MRPC)\n")
    f.write("="*70 + "\n\n")
    f.write(f"Accuracy: {baseline_acc:.4f} ({baseline_acc*100:.2f}%)\n")
    f.write(f"Precision: {baseline_p:.4f}\n")
    f.write(f"Recall: {baseline_r:.4f}\n")
    f.write(f"F1-Score: {baseline_f1:.4f}\n")

print("✓ Baseline saved")

# ================================================================
# 4. STEP 2: Layer-wise Analysis (Probes + Transcoder SAEs)
# ================================================================
print("\n" + "="*70)
print("STEP 2: LAYER-WISE ANALYSIS (Qwen3-0.6B + Transcoders on MRPC)")
print("="*70)

layer_performance = {}
sae_feature_stats = {}

TOP_K = 10
release_qwen = "mwhanna-qwen3-0.6b-transcoders-lowl0"

for layer_num in range(n_layers):
    print(f"\n{'='*70}")
    print(f"LAYER {layer_num} ANALYSIS")
    print(f"{'='*70}")

    # ----------------------------------------------------------
    # Part A: Raw representation classifier
    # ----------------------------------------------------------
    print("\n--- Part A: Raw Representation Classifier (Hidden state) ---")

    print("Extracting training representations...")
    train_reps = []
    train_labels = []

    with torch.no_grad():
        for idx in tqdm(range(len(train_dataset)), desc=f"Train L{layer_num}"):
            combined = combine_sentences(train_dataset[idx])
            label = train_dataset[idx]["label"]

            layer_h = get_layer_rep(combined, layer_num)   # (1, seq, d_model)
            pooled = layer_h.mean(dim=1)                  # (1, d_model)
            pooled_flat = pooled[0].to(torch.float32).cpu().numpy().flatten()

            train_reps.append(pooled_flat)
            train_labels.append(label)

    X_train = np.array(train_reps)
    y_train = np.array(train_labels)

    print("Extracting validation representations...")
    val_reps = []
    val_labels_raw = []

    with torch.no_grad():
        for idx in tqdm(range(len(val_dataset)), desc=f"Val L{layer_num}"):
            combined = combine_sentences(val_dataset[idx])
            label = val_dataset[idx]["label"]

            layer_h = get_layer_rep(combined, layer_num)
            pooled = layer_h.mean(dim=1)
            pooled_flat = pooled[0].to(torch.float32).cpu().numpy().flatten()

            val_reps.append(pooled_flat)
            val_labels_raw.append(label)

    X_val = np.array(val_reps)
    y_val = np.array(val_labels_raw)

    print("Training classifier...")
    clf = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')
    clf.fit(X_train, y_train)

    predictions = clf.predict(X_val)

    acc = accuracy_score(y_val, predictions)
    p, r, f1, _ = precision_recall_fscore_support(y_val, predictions, average='binary')
    cm = confusion_matrix(y_val, predictions)

    layer_performance[layer_num] = {
        "accuracy": acc,
        "precision": p,
        "recall": r,
        "f1_score": f1,
        "improvement": acc - baseline_acc,
        "confusion_matrix": cm,
    }

    print(f"Layer {layer_num} Accuracy: {acc:.4f} ({acc*100:.2f}%)")
    print(f"Improvement over baseline: {(acc - baseline_acc)*100:+.2f}%")

    # ----------------------------------------------------------
    # Part B: SAE feature analysis
    # ----------------------------------------------------------
    print("\n--- Part B: SAE Feature Analysis (Transcoders) ---")

    sae_id_qwen = f"layer_{layer_num}"
    try:
        try:
            sae_qwen = SAE.from_pretrained(release_qwen, sae_id_qwen)
        except:
            sae_qwen = SAE.from_pretrained(release_qwen, sae_id_qwen)[0]

        sae_qwen.to(device)
        sae_qwen.eval()
        print(f"Loaded Qwen3 SAE: {sae_id_qwen}")
    except Exception as e:
        print(f"Could not load SAE for layer {layer_num}: {e}")
        sae_feature_stats[layer_num] = {}
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        continue

    print("Extracting SAE features...")

    pos_active_features = set()  # Paraphrase
    neg_active_features = set()  # Not paraphrase

    pos_feature_activations = {}
    neg_feature_activations = {}

    pos_feature_counts = Counter()
    neg_feature_counts = Counter()

    total_pos = 0
    total_neg = 0

    with torch.no_grad():
        for idx in tqdm(range(len(val_dataset)), desc=f"SAE L{layer_num}"):
            combined = combine_sentences(val_dataset[idx])
            label = val_dataset[idx]["label"]

            layer_h = get_layer_rep(combined, layer_num)        # (1, seq, d_model)
            sae_feats = sae_qwen.encode(layer_h)                # (1, seq, d_sae)

            pooled_features = sae_feats.mean(dim=1)[0].to(torch.float32).cpu().numpy().flatten()

            active_indices = np.where(pooled_features > 0)[0]
            active_values = pooled_features[active_indices]

            if label == 1:  # Paraphrase
                total_pos += 1
                for feat_idx, act_val in zip(active_indices, active_values):
                    pos_active_features.add(feat_idx)
                    pos_feature_counts[feat_idx] += 1
                    pos_feature_activations.setdefault(feat_idx, []).append(act_val)
            else:  # Not paraphrase
                total_neg += 1
                for feat_idx, act_val in zip(active_indices, active_values):
                    neg_active_features.add(feat_idx)
                    neg_feature_counts[feat_idx] += 1
                    neg_feature_activations.setdefault(feat_idx, []).append(act_val)

    common_features = pos_active_features & neg_active_features
    pos_only_features = pos_active_features - neg_active_features
    neg_only_features = neg_active_features - pos_active_features

    pos_avg_activations = {f: np.mean(acts) for f, acts in pos_feature_activations.items()}
    neg_avg_activations = {f: np.mean(acts) for f, acts in neg_feature_activations.items()}

    top5_pos_by_activation = sorted(
        pos_avg_activations.items(), key=lambda x: x[1], reverse=True
    )[:5]
    top5_neg_by_activation = sorted(
        neg_avg_activations.items(), key=lambda x: x[1], reverse=True
    )[:5]

    topk_pos_by_frequency = pos_feature_counts.most_common(TOP_K)
    topk_neg_by_frequency = neg_feature_counts.most_common(TOP_K)

    top5_pos_by_frequency = pos_feature_counts.most_common(5)
    top5_neg_by_frequency = neg_feature_counts.most_common(5)

    topk_pos_ids = {feat for feat, _ in topk_pos_by_frequency}
    topk_neg_ids = {feat for feat, _ in topk_neg_by_frequency}
    topk_common_ids = topk_pos_ids & topk_neg_ids

    sae_feature_stats[layer_num] = {
        "total_pos_features": len(pos_active_features),
        "total_neg_features": len(neg_active_features),
        "common_features": len(common_features),
        "pos_only_features": len(pos_only_features),
        "neg_only_features": len(neg_only_features),
        "top5_pos_by_activation": top5_pos_by_activation,
        "top5_neg_by_activation": top5_neg_by_activation,
        "top5_pos_by_frequency": top5_pos_by_frequency,
        "top5_neg_by_frequency": top5_neg_by_frequency,
        "topk_pos_by_frequency": topk_pos_by_frequency,
        "topk_neg_by_frequency": topk_neg_by_frequency,
        "topk_common_ids": topk_common_ids,
        "total_pos_samples": total_pos,
        "total_neg_samples": total_neg,
    }

    # ----------------------------------------------------------
    # Save per-layer detailed analysis
    # ----------------------------------------------------------
    with open(f"/kaggle/working/results_mrpc_qwen3/layer_{layer_num}_complete_analysis.txt", "w") as f:
        f.write("="*70 + "\n")
        f.write(f"LAYER {layer_num} - COMPLETE ANALYSIS (Qwen3-0.6B on MRPC)\n")
        f.write("="*70 + "\n\n")

        f.write("A. LAYER PERFORMANCE (Raw Representations)\n")
        f.write("-"*70 + "\n")
        f.write(f"Accuracy: {acc:.4f} ({acc*100:.2f}%)\n")
        f.write(f"Precision: {p:.4f}\n")
        f.write(f"Recall: {r:.4f}\n")
        f.write(f"F1-Score: {f1:.4f}\n")
        f.write(f"Baseline Accuracy: {baseline_acc:.4f}\n")
        f.write(f"Improvement over baseline: {(acc - baseline_acc)*100:+.2f}%\n\n")

        f.write("Confusion Matrix:\n")
        f.write("              Predicted\n")
        f.write("         Not-Para  Para\n")
        f.write(f"Actual 0  [{cm[0,0]:5d}  {cm[0,1]:5d}]\n")
        f.write(f"       1  [{cm[1,0]:5d}  {cm[1,1]:5d}]\n\n")

        f.write("B. SAE FEATURE COUNTS\n")
        f.write("-"*70 + "\n")
        f.write(f"Total PARAPHRASE samples: {total_pos}\n")
        f.write(f"Total NON-PARAPHRASE samples: {total_neg}\n\n")
        f.write(f"Total features activated for PARAPHRASE: {len(pos_active_features)}\n")
        f.write(f"Total features activated for NON-PARAPHRASE: {len(neg_active_features)}\n")
        f.write(f"COMMON features (activated for both): {len(common_features)}\n")
        f.write(f"UNIQUE to PARAPHRASE only: {len(pos_only_features)}\n")
        f.write(f"UNIQUE to NON-PARAPHRASE only: {len(neg_only_features)}\n\n")

        f.write("C. TOP 5 MOST ACTIVATING FEATURES (PARAPHRASE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, avg_act) in enumerate(top5_pos_by_activation, 1):
            freq = pos_feature_counts[feat_idx]
            pct = freq / total_pos * 100 if total_pos > 0 else 0.0
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(
                f"{rank}. Feature {feat_idx}: avg_activation={avg_act:.4f}, "
                f"frequency={freq}/{total_pos} ({pct:.1f}%) | {status}\n"
            )

        f.write("\nD. TOP 5 MOST ACTIVATING FEATURES (NON-PARAPHRASE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, avg_act) in enumerate(top5_neg_by_activation, 1):
            freq = neg_feature_counts[feat_idx]
            pct = freq / total_neg * 100 if total_neg > 0 else 0.0
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(
                f"{rank}. Feature {feat_idx}: avg_activation={avg_act:.4f}, "
                f"frequency={freq}/{total_neg} ({pct:.1f}%) | {status}\n"
            )

        f.write("\nE. TOP 5 MOST FREQUENT FEATURES (PARAPHRASE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, count) in enumerate(top5_pos_by_frequency, 1):
            pct = count / total_pos * 100 if total_pos > 0 else 0.0
            avg_act = pos_avg_activations.get(feat_idx, 0.0)
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(
                f"{rank}. Feature {feat_idx}: count={count} ({pct:.1f}%), "
                f"avg_activation={avg_act:.4f} | {status}\n"
            )

        f.write("\nF. TOP 5 MOST FREQUENT FEATURES (NON-PARAPHRASE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, count) in enumerate(top5_neg_by_frequency, 1):
            pct = count / total_neg * 100 if total_neg > 0 else 0.0
            avg_act = neg_avg_activations.get(feat_idx, 0.0)
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(
                f"{rank}. Feature {feat_idx}: count={count} ({pct:.1f}%), "
                f"avg_activation={avg_act:.4f} | {status}\n"
            )

        f.write(f"\nG. TOP {TOP_K} MOST FREQUENT FEATURES (PARAPHRASE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, count) in enumerate(topk_pos_by_frequency, 1):
            pct = count / total_pos * 100 if total_pos > 0 else 0.0
            f.write(
                f"{rank}. Feature {feat_idx}: count={count} ({pct:.1f}%)\n"
            )

        f.write(f"\nH. TOP {TOP_K} MOST FREQUENT FEATURES (NON-PARAPHRASE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, count) in enumerate(topk_neg_by_frequency, 1):
            pct = count / total_neg * 100 if total_neg > 0 else 0.0
            f.write(
                f"{rank}. Feature {feat_idx}: count={count} ({pct:.1f}%)\n"
            )

        f.write(
            f"\nI. COMMON FEATURES AMONG TOP-{TOP_K} PARA & NON-PARA\n"
        )
        f.write("-"*70 + "\n")
        f.write(f"Count: {len(topk_common_ids)}\n")
        if len(topk_common_ids) > 0:
            f.write(
                "Example IDs: "
                + ", ".join(str(x) for x in sorted(list(topk_common_ids))[:20])
                + "\n"
            )

    print(f"✓ Layer {layer_num} complete analysis saved")

    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

# ================================================================
# 5. FINAL SUMMARY
# ================================================================
print("\n" + "="*70)
print("FINAL SUMMARY")
print("="*70)

best_layer = max(layer_performance.items(), key=lambda x: x[1]["accuracy"])
worst_layer = min(layer_performance.items(), key=lambda x: x[1]["accuracy"])

print(
    f"\n{'Layer':<6} {'Acc%':<8} {'Improv':<10} "
    f"{'Para Feat':<10} {'NonPara':<10} {'Common':<10}"
)
print("-"*90)
for layer_num in sorted(layer_performance.keys()):
    perf = layer_performance[layer_num]
    stats = sae_feature_stats.get(layer_num, {})
    print(
        f"L{layer_num:<5} {perf['accuracy']*100:5.2f}%   "
        f"{perf['improvement']*100:+6.2f}%    "
        f"{stats.get('total_pos_features', 'N/A'):<10} "
        f"{stats.get('total_neg_features', 'N/A'):<10} "
        f"{stats.get('common_features', 'N/A'):<10}"
    )

print(
    f"\n✓ Best layer: Layer {best_layer[0]} "
    f"({best_layer[1]['accuracy']*100:.2f}% accuracy)"
)
print(
    f"✓ Worst layer: Layer {worst_layer[0]} "
    f"({worst_layer[1]['accuracy']*100:.2f}% accuracy)"
)

# Get top 2 layers for interpretability
top_2_layers = sorted(layer_performance.items(), key=lambda x: x[1]["accuracy"], reverse=True)[:2]
top_2_layer_nums = [layer_num for layer_num, _ in top_2_layers]
print(f"\nTop 2 layers for interpretability: {top_2_layer_nums}")

with open("/kaggle/working/results_mrpc_qwen3/final_summary.txt", "w") as f:
    f.write("="*70 + "\n")
    f.write("FINAL SUMMARY - LAYER-WISE ANALYSIS (Qwen3 + Transcoders on MRPC)\n")
    f.write("="*70 + "\n\n")

    f.write("1. BASELINE (Zero-Shot Prompting)\n")
    f.write("-"*70 + "\n")
    f.write(f"Accuracy: {baseline_acc*100:.2f}%\n")
    f.write(f"F1-Score: {baseline_f1:.4f}\n\n")

    f.write("2. LAYER-WISE PERFORMANCE & SAE FEATURE STATISTICS\n")
    f.write("-"*70 + "\n")
    f.write(
        f"{'Layer':<6} {'Acc%':<8} {'Improv':<10} "
        f"{'Para Feat':<10} {'NonPara':<10} {'Common':<10}\n"
    )
    f.write("-"*90 + "\n")
    for layer_num in sorted(layer_performance.keys()):
        perf = layer_performance[layer_num]
        stats = sae_feature_stats.get(layer_num, {})
        f.write(
            f"L{layer_num:<5} {perf['accuracy']*100:5.2f}%   "
            f"{perf['improvement']*100:+6.2f}%    "
            f"{stats.get('total_pos_features', 'N/A'):<10} "
            f"{stats.get('total_neg_features', 'N/A'):<10} "
            f"{stats.get('common_features', 'N/A'):<10}\n"
        )

    f.write("\n3. KEY FINDINGS\n")
    f.write("-"*70 + "\n")
    f.write(f"Best Performing Layer: Layer {best_layer[0]}\n")
    f.write(f"  Accuracy: {best_layer[1]['accuracy']*100:.2f}%\n")
    f.write(
        f"  Improvement over baseline: "
        f"{best_layer[1]['improvement']*100:+.2f}%\n\n"
    )
    f.write(f"Worst Performing Layer: Layer {worst_layer[0]}\n")
    f.write(f"  Accuracy: {worst_layer[1]['accuracy']*100:.2f}%\n\n")
    f.write(f"Top 2 Layers: {top_2_layer_nums}\n\n")
    f.write("INTERPRETATION:\n")
    f.write("- MRPC = paraphrase detection (semantic equivalence)\n")
    f.write("- Para-specific features = semantic similarity detectors\n")
    f.write("- Non-para features = divergence/difference signals\n")
    f.write("- Overlap shows shared semantic understanding\n")

print("\n✓ All results saved to /kaggle/working/results_mrpc_qwen3/")
print("="*70)

# ================================================================
# 6. STEP 3: GROQ INTERPRETABILITY FOR TOP 2 LAYERS
# ================================================================
print("\n" + "="*70)
print("STEP 3: GROQ INTERPRETABILITY FOR TOP 2 LAYERS")
print("="*70)

import re
from scipy.stats import pearsonr
from groq import Groq
from torch.utils.data import DataLoader

# Setup Groq
os.environ["GROQ_API_KEY"] = user_secrets.get_secret("GROQ_API_KEY")
client = Groq(api_key=os.environ["GROQ_API_KEY"])

def chat_with_llama(prompt, model="llama-3.1-8b-instant", max_tokens=150):
    resp = client.chat.completions.create(
        messages=[
            {"role": "system", "content": "You are a helpful interpretability assistant."},
            {"role": "user", "content": prompt},
        ],
        model=model,
        max_tokens=max_tokens,
        temperature=0.7,
    )
    return resp.choices[0].message.content.strip()

# Dataset wrapper
val_combined = [combine_sentences(ex) for ex in val_dataset]

class TextDataset(torch.utils.data.Dataset):
    def __init__(self, sentences):
        self.sentences = sentences
    def __len__(self):
        return len(self.sentences)
    def __getitem__(self, idx):
        return self.sentences[idx]

val_text_ds = TextDataset(val_combined)

# SAE wrapper
class SAEWithActs(torch.nn.Module):
    def __init__(self, sae_model):
        super().__init__()
        self.sae = sae_model
        self.activations = None
        hook_module = getattr(self.sae, "hook_sae_acts_post", None)
        if hook_module is None:
            raise ValueError("hook_sae_acts_post not found on SAE model.")
        hook_module.register_forward_hook(self._hook)

    def _hook(self, module, inp, out):
        self.activations = out.detach()

    def forward(self, sae_input):
        _ = self.sae(sae_input)
        return self.activations

    def get_acts(self, sae_input):
        self.eval()
        with torch.no_grad():
            _ = self.forward(sae_input)
            return self.activations

# Helper functions
def get_layer_reps_batch(text_batch, layer_idx, max_length=128):
    enc = tokenizer(
        list(text_batch),
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=max_length,
    ).to(device)

    with torch.no_grad():
        out = model(
            **enc,
            output_hidden_states=True,
            use_cache=False,
        )

    hidden_states = out.hidden_states
    layer_h = hidden_states[layer_idx + 1]
    return layer_h, enc["attention_mask"]

def top_k_global_features_for_layer(layer_num, sae_model, k=10, max_batches=None):
    sae_wrap = SAEWithActs(sae_model).to(device)
    counter = Counter()
    dataloader = DataLoader(val_text_ds, batch_size=32, shuffle=False)

    for i, batch_texts in enumerate(tqdm(dataloader, desc=f"Counting L{layer_num}")):
        if max_batches is not None and i >= max_batches:
            break

        layer_h, attn_mask = get_layer_reps_batch(batch_texts, layer_num)
        latents = sae_wrap.get_acts(layer_h)

        if attn_mask is not None:
            mask = attn_mask.unsqueeze(-1)
            latents = latents * mask

        active = (latents > 0).any(dim=1)
        for row in active:
            idxs = row.nonzero(as_tuple=True)[0].tolist()
            counter.update(idxs)

    topk = counter.most_common(k)
    print(f"Layer {layer_num} top-{k}: {topk}")
    return [idx for idx, _ in topk]

def extract_feature_acts(layer_num, sae_wrap, feature_idx, max_batches=None):
    acts_all, texts_all = [], []
    dataloader = DataLoader(val_text_ds, batch_size=32, shuffle=False)

    for i, batch_texts in enumerate(tqdm(dataloader, desc=f"Extracting L{layer_num} F{feature_idx}")):
        if max_batches is not None and i >= max_batches:
            break

        layer_h, attn_mask = get_layer_reps_batch(batch_texts, layer_num)
        latents = sae_wrap.get_acts(layer_h)

        if attn_mask is not None:
            mask = attn_mask.unsqueeze(-1)
            latents = latents * mask

        feat_acts = latents[:, :, feature_idx].detach().cpu().numpy()
        for a_sent, txt in zip(feat_acts, batch_texts):
            acts_all.append(a_sent)
            texts_all.append(txt)

    return acts_all, texts_all

def interpret_feature(layer_num, sae_model, feature_idx, report_path, max_batches=None):
    sae_wrap = SAEWithActs(sae_model).to(device)

    acts_all, texts_all = extract_feature_acts(layer_num, sae_wrap, feature_idx, max_batches)

    # Top examples
    scores = [np.sum(a) for a in acts_all]
    idxs = np.argsort(scores)[::-1][:20]
    top_acts = [acts_all[i] for i in idxs[:5]]
    top_texts = [texts_all[i][:80] for i in idxs[:5]]

    print(f"\nTop 5 for L{layer_num} F{feature_idx}:")
    for txt in top_texts:
        print(f"  {txt}...")

    # Interpretation
    prompt = (
        f"Analyzing Qwen3 SAE feature on MRPC paraphrase detection. "
        "Describe in ONE sentence what pattern this detects:\n\n"
    )
    for i, (txt, acts) in enumerate(zip(top_texts, top_acts), 1):
        prompt += f"{i}. {txt}\nActivations: {acts.tolist()}\n\n"
    prompt += "Explanation:"

    interpretation = chat_with_llama(prompt, max_tokens=100)
    print(f"Interpretation: {interpretation}")

    # Evaluation
    eval_texts = [texts_all[i][:80] for i in idxs[5:10]]
    eval_acts = [acts_all[i] for i in idxs[5:10]]

    pred_scores = []
    for txt in eval_texts:
        pred = chat_with_llama(
            f'Feature: "{interpretation}"\nRate 0-10 for: "{txt}"\nScore:',
            max_tokens=10
        )
        m = re.search(r"\d+", pred)
        pred_scores.append(float(m.group()) if m else 5.0)

    actual_scores = [np.mean(a) * 10 for a in eval_acts]
    corr = pearsonr(actual_scores, pred_scores)[0] if len(actual_scores) > 1 else 0.0

    print(f"Pearson: {corr:.3f}")

    # Save
    with open(report_path, "a") as f:
        f.write(f"Layer {layer_num}, Feature {feature_idx}\n")
        f.write("-"*70 + "\n")
        f.write(f"Interpretation: {interpretation}\n")
        f.write(f"Pearson correlation: {corr:.3f}\n\n")
        f.write("Top activating examples:\n")
        for txt, acts in zip(top_texts, top_acts):
            f.write(f"  - {txt}\n")
        f.write("\n" + "="*70 + "\n\n")

    return corr

# Run for top 2 layers
INTERP_TOP_K = 10

for layer_idx in top_2_layer_nums:
    print(f"\n{'='*70}\nLAYER {layer_idx}\n{'='*70}")

    sae_id = f"layer_{layer_idx}"
    try:
        sae_model = SAE.from_pretrained(release_qwen, sae_id)[0]
    except:
        sae_model = SAE.from_pretrained(release_qwen, sae_id)

    sae_model.to(device).eval()

    top_feats = top_k_global_features_for_layer(layer_idx, sae_model, INTERP_TOP_K, None)

    report_file = f"/kaggle/working/results_mrpc_qwen3/layer{layer_idx}_top{INTERP_TOP_K}_interpretability.txt"
    with open(report_file, "w") as f:
        f.write(f"Qwen3-0.6B MRPC Layer {layer_idx}\n{'='*70}\n\n")

    for feat in top_feats:
        print(f"\n--- Feature {feat} ---")
        try:
            interpret_feature(layer_idx, sae_model, feat, report_file, None)
        except Exception as e:
            print(f"Error: {e}")

        gc.collect()
        torch.cuda.empty_cache()

    print(f"\n✓ Saved to {report_file}")

print("\n✓ COMPLETE - Qwen3-0.6B MRPC Analysis")