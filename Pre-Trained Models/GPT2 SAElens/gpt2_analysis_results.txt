Using device: cuda
Loading GPT-2 Small model...
Loaded pretrained model gpt2-small into HookedTransformer
Model has 12 layers (0-11)
Loading SST-2 dataset...
Train samples: 67349
Validation samples: 872

======================================================================
TASK 1: BASELINE PERFORMANCE - ZERO-SHOT PROMPTING
======================================================================
### BASELINE RESULTS ###
Accuracy: 0.5344 (53.44%)
Precision: 0.5227
Recall: 0.9842
F1-Score: 0.6828

Confusion Matrix:
              Neg    Pos
Actual Neg  [   29    399]
       Pos  [    7    437]

✓ Baseline results saved

======================================================================
TASK 2: SAE FEATURE EXTRACTION
======================================================================

Checking hook dimensions...
blocks.11.hook_mlp_out shape: torch.Size([1, 2, 768])
blocks.11.attn.hook_z shape: torch.Size([1, 2, 12, 64])

Loading pretrained SAE for attention outputs...
SAE loaded: blocks.11.hook_z
SAE feature dimension: 24576
SAE expects input dimension: 768
Using hook: blocks.11.attn.hook_z
Hook output shape: torch.Size([1, 2, 12, 64])
Expected by SAE: 768

Extracting features from training set...

Feature extraction complete!
Training features shape: (67349, 24576)
Validation features shape: (872, 24576)
✓ Features saved

Training classifier on SAE features...
✓ Classifier saved

### SAE-BASED RESULTS ###
Accuracy: 0.7053 (70.53%)
Precision: 0.7140
Recall: 0.7027
F1-Score: 0.7083

Confusion Matrix:
              Neg    Pos
Actual Neg  [  303    125]
       Pos  [  132    312]
✓ SAE results saved

======================================================================
TASK 3: COMPREHENSIVE FEATURE ANALYSIS
======================================================================

======================================================================
A. OVERALL FEATURE STATISTICS
======================================================================
Total samples - POSITIVE: 37569, NEGATIVE: 29780

Unique features:
  POSITIVE: 2917
  NEGATIVE: 2913
  Common: 2701
  POSITIVE-only: 216
  NEGATIVE-only: 212

Jaccard Similarity: 0.8632
→ SIMILAR feature sets (overlapping representations)

======================================================================
B. UNCOMMON FEATURES (<5%)
======================================================================
Uncommon POSITIVE: 2805 (96.2%)
Uncommon NEGATIVE: 2790 (95.8%)
Very rare (<1%) - POS: 2586, NEG: 2550

### Top 10 Uncommon Important POSITIVE Features ###
  Feature 13331:    7 times (0.02%) | Weight: +2.6447
  Feature 15398:    3 times (0.01%) | Weight: -2.2479
  Feature 14269:    8 times (0.02%) | Weight: -2.2394
  Feature 21034:    6 times (0.02%) | Weight: -2.2088
  Feature 13540:   18 times (0.05%) | Weight: +2.1583
  Feature  3288:   25 times (0.07%) | Weight: +2.1449
  Feature 12822:    8 times (0.02%) | Weight: +2.0614
  Feature  9353:   13 times (0.03%) | Weight: +2.0595
  Feature  8636:    5 times (0.01%) | Weight: -2.0165
  Feature 18386:   60 times (0.16%) | Weight: +1.9581

### Top 10 Uncommon Important NEGATIVE Features ###
  Feature 13331:    1 times (0.00%) | Weight: +2.6447
  Feature 15398:   33 times (0.11%) | Weight: -2.2479
  Feature 14269:   29 times (0.10%) | Weight: -2.2394
  Feature 21034:   25 times (0.08%) | Weight: -2.2088
  Feature 13540:    1 times (0.00%) | Weight: +2.1583
  Feature  3288:    5 times (0.02%) | Weight: +2.1449
  Feature 12822:    9 times (0.03%) | Weight: +2.0614
  Feature  9353:    3 times (0.01%) | Weight: +2.0595
  Feature  8636:   21 times (0.07%) | Weight: -2.0165
  Feature 18386:   11 times (0.04%) | Weight: +1.9581

======================================================================
FINAL SUMMARY
======================================================================
Baseline: Accuracy=53.44%, F1=0.6828
SAE-Based: Accuracy=70.53%, F1=0.7083
Improvement: +17.09%
Feature overlap (Jaccard): 0.8632
======================================================================
✓ Complete!
