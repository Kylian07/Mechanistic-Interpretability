======================================================================
FINAL SUMMARY - LAYER-WISE ANALYSIS
======================================================================

1. BASELINE (Zero-Shot Prompting)
----------------------------------------------------------------------
Accuracy: 53.44%
F1-Score: 0.6828

2. LAYER-WISE PERFORMANCE & SAE FEATURE STATISTICS
----------------------------------------------------------------------
Layer  Acc%     Improv     Pos Feat   Neg Feat   Common     Pos Only   Neg Only  
------------------------------------------------------------------------------------
L0     79.01%   +25.57%    4114       4054       2419       1695       1635      
L1     77.98%   +24.54%    4542       4552       3306       1236       1246      
L2     80.50%   +27.06%    8122       8087       5859       2263       2228      
L3     81.88%   +28.44%    12422      12311      9593       2829       2718      
L4     82.00%   +28.56%    14167      14252      11503      2664       2749      
L5     83.60%   +30.16%    10126      9773       6985       3141       2788      
L6     83.49%   +30.05%    9102       9341       7405       1697       1936      
L7     84.86%   +31.42%    8279       8338       6272       2007       2066      
L8     84.40%   +30.96%    7242       7326       5703       1539       1623      
L9     81.19%   +27.75%    4720       4668       3776       944        892       
L10    81.65%   +28.21%    4459       4245       3333       1126       912       
L11    81.65%   +28.21%    1510       1542       1147       363        395       

3. TOP 5 MOST ACTIVATING FEATURES PER LAYER
----------------------------------------------------------------------

Layer 0:
  POSITIVE (by activation): F23778(0.231) F451(0.220) F22036(0.213) F6440(0.205) F11379(0.203) 
  NEGATIVE (by activation): F3500(0.398) F9538(0.310) F21403(0.247) F16038(0.241) F451(0.235) 

Layer 1:
  POSITIVE (by activation): F16616(0.577) F17148(0.405) F21010(0.321) F1473(0.315) F10043(0.302) 
  NEGATIVE (by activation): F14210(0.451) F17148(0.433) F23994(0.412) F3219(0.403) F12326(0.342) 

Layer 2:
  POSITIVE (by activation): F11616(0.832) F19311(0.577) F13413(0.554) F5792(0.484) F13340(0.471) 
  NEGATIVE (by activation): F24044(0.663) F3992(0.638) F21273(0.638) F12973(0.615) F13261(0.606) 

Layer 3:
  POSITIVE (by activation): F13699(0.648) F12546(0.641) F1285(0.607) F8785(0.523) F16949(0.519) 
  NEGATIVE (by activation): F16315(0.752) F13653(0.647) F9854(0.593) F8803(0.583) F16854(0.560) 

Layer 4:
  POSITIVE (by activation): F7125(0.763) F14433(0.630) F19390(0.614) F820(0.588) F12921(0.583) 
  NEGATIVE (by activation): F23346(1.002) F5392(0.684) F2586(0.635) F14671(0.525) F14544(0.523) 

Layer 5:
  POSITIVE (by activation): F29473(1.547) F23008(0.903) F16496(0.849) F26007(0.641) F29944(0.626) 
  NEGATIVE (by activation): F7158(1.631) F20575(1.111) F11239(0.844) F10777(0.834) F12076(0.815) 

Layer 6:
  POSITIVE (by activation): F15814(1.303) F687(0.782) F16820(0.629) F1960(0.561) F12027(0.487) 
  NEGATIVE (by activation): F5294(1.281) F23469(1.055) F11685(0.891) F4249(0.848) F23173(0.744) 

Layer 7:
  POSITIVE (by activation): F7902(0.587) F15742(0.461) F37634(0.444) F30496(0.411) F14103(0.391) 
  NEGATIVE (by activation): F47819(0.967) F25281(0.827) F12448(0.668) F7367(0.605) F32370(0.504) 

Layer 8:
  POSITIVE (by activation): F15846(0.832) F18572(0.769) F14626(0.606) F20589(0.538) F7751(0.527) 
  NEGATIVE (by activation): F15189(0.973) F8523(0.699) F13219(0.596) F16149(0.553) F18766(0.478) 

Layer 9:
  POSITIVE (by activation): F17376(1.185) F13744(0.464) F1591(0.369) F14845(0.296) F13106(0.293) 
  NEGATIVE (by activation): F17376(1.076) F5860(0.438) F9274(0.428) F6689(0.389) F10667(0.379) 

Layer 10:
  POSITIVE (by activation): F3470(0.779) F5386(0.541) F18109(0.539) F15907(0.496) F16313(0.453) 
  NEGATIVE (by activation): F22893(0.884) F10373(0.578) F21871(0.512) F1202(0.501) F8201(0.471) 

Layer 11:
  POSITIVE (by activation): F1958(2.719) F8228(0.524) F20117(0.400) F17765(0.400) F22755(0.388) 
  NEGATIVE (by activation): F1958(2.904) F20920(0.906) F5056(0.527) F21247(0.516) F6914(0.476) 

4. KEY FINDINGS
----------------------------------------------------------------------
Best Performing Layer: Layer 7
  Accuracy: 84.86%
  Improvement over baseline: +31.42%
  â†’ This layer encodes the most sentiment information

Worst Performing Layer: Layer 1
  Accuracy: 77.98%

INTERPRETATION:
- Higher accuracy = more sentiment information linearly accessible in layer
- More unique features = better class separation in SAE space
- Fewer common features = more distinct representations per sentiment
