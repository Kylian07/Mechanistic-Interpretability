# -*- coding: utf-8 -*-
"""Pretrained GPT2_SAE_SAElens

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/kylian007/pretrained-gpt2-sae-saelens.23486761-8142-456d-b73b-2f042327f5bb.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251204/auto/storage/goog4_request%26X-Goog-Date%3D20251204T214846Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5e9b89da980671b45242c9e4de2d8e460967ef17f06cde1dab166bb1c98e7d921a9875e9ccd237602afbaf52aa26835bac232c688ed9931b5f728cfb073ef05439b26acbabc5a792018356b849a0e0f0fc063c95f27bc7821cfaa9c75b4e602681560e5cab83c069f740ab36861965933f99716c0944a3307503b9d2b8f1f43496c7759aadd0a5154c9bddcd31b605e358cd4b72dbe235957f78a8ba361965d73ccb9ebd01af475e03ac4d81a04a9b9624134a72e3c202899d1960769a25053b0cfe7d707a7219e0ccbc70a10659f39ba71dc7fad96ac0d591aa37f66f1668bb2fba4051077c8c5f5e84c3819046a7355f2b16a1f9f0e73baf487cd6c43c4883
"""

!pip install sae-lens

import torch
from datasets import load_dataset
from transformer_lens import HookedTransformer
from sae_lens import SAE
from tqdm import tqdm
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import numpy as np
from collections import Counter
import os

# Kaggle directories
os.makedirs('/kaggle/working/hf_cache', exist_ok=True)
os.makedirs('/kaggle/working/results', exist_ok=True)

os.environ['HF_HOME'] = '/kaggle/working/hf_cache'
os.environ['TRANSFORMERS_CACHE'] = '/kaggle/working/hf_cache'
os.environ['HF_DATASETS_CACHE'] = '/kaggle/working/hf_cache'

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Load GPT-2 Small
print("Loading GPT-2 Small model...")
model = HookedTransformer.from_pretrained("gpt2-small", device=device)
model.eval()

print(f"Model has {model.cfg.n_layers} layers (0-{model.cfg.n_layers-1})")

# Load SST-2 dataset
print("Loading SST-2 dataset...")
dataset = load_dataset("glue", "sst2")
train_dataset = dataset["train"]
val_dataset = dataset["validation"]

print(f"Train samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")

# ============================================================================
# STEP 1: Baseline - Zero-Shot Prompting
# ============================================================================
print("\n" + "="*70)
print("STEP 1: BASELINE - ZERO-SHOT PROMPTING")
print("="*70)

baseline_predictions = []
baseline_labels = []

with torch.no_grad():
    for idx in tqdm(range(len(val_dataset)), desc="Zero-Shot Evaluation"):
        sentence = val_dataset[idx]["sentence"]
        true_label = val_dataset[idx]["label"]
        
        prompt = f"""Classify the sentiment as positive or negative.

Sentence: {sentence}
Sentiment:"""
        
        tokens = model.to_tokens(prompt)
        logits = model(tokens)
        
        next_token_logits = logits[0, -1, :]
        next_token_id = torch.argmax(next_token_logits).item()
        generated_text = model.tokenizer.decode([next_token_id]).strip().lower()
        
        if "positive" in generated_text or generated_text.startswith("pos"):
            prediction = 1
        elif "negative" in generated_text or generated_text.startswith("neg"):
            prediction = 0
        else:
            pos_token_id = model.tokenizer.encode(" positive")[0]
            neg_token_id = model.tokenizer.encode(" negative")[0]
            
            if next_token_logits[pos_token_id] > next_token_logits[neg_token_id]:
                prediction = 1
            else:
                prediction = 0
        
        baseline_predictions.append(prediction)
        baseline_labels.append(true_label)

baseline_predictions = np.array(baseline_predictions)
baseline_labels = np.array(baseline_labels)

baseline_acc = accuracy_score(baseline_labels, baseline_predictions)
baseline_p, baseline_r, baseline_f1, _ = precision_recall_fscore_support(
    baseline_labels, baseline_predictions, average='binary'
)

print(f"\nBaseline Accuracy: {baseline_acc:.4f} ({baseline_acc*100:.2f}%)")
print(f"F1-Score: {baseline_f1:.4f}")

# Save baseline results
with open('/kaggle/working/results/baseline_results.txt', 'w') as f:
    f.write("="*70 + "\n")
    f.write("BASELINE - ZERO-SHOT PROMPTING\n")
    f.write("="*70 + "\n\n")
    f.write(f"Accuracy: {baseline_acc:.4f} ({baseline_acc*100:.2f}%)\n")
    f.write(f"Precision: {baseline_p:.4f}\n")
    f.write(f"Recall: {baseline_r:.4f}\n")
    f.write(f"F1-Score: {baseline_f1:.4f}\n")

print("✓ Baseline saved")

# ============================================================================
# STEP 2: Layer-wise Performance + SAE Feature Analysis
# ============================================================================
print("\n" + "="*70)
print("STEP 2: LAYER-WISE ANALYSIS")
print("="*70)

layer_performance = {}
sae_feature_stats = {}

for layer_num in range(model.cfg.n_layers):
    print(f"\n{'='*70}")
    print(f"LAYER {layer_num} ANALYSIS")
    print(f"{'='*70}")
    
    hook_name = f"blocks.{layer_num}.attn.hook_z"
    
    # ========================================================================
    # PART A: Raw Representation Classifier (Layer Performance)
    # ========================================================================
    print(f"\n--- Part A: Raw Representation Classifier ---")
    
    # Extract RAW representations from training set
    print("Extracting training representations...")
    train_reps = []
    train_labels = []
    
    with torch.no_grad():
        for idx in tqdm(range(len(train_dataset)), desc=f"Train L{layer_num}"):
            sentence = train_dataset[idx]["sentence"]
            label = train_dataset[idx]["label"]
            
            tokens = model.to_tokens(sentence)
            _, cache = model.run_with_cache(tokens)
            
            layer_acts = cache[hook_name]
            pooled = layer_acts.mean(dim=1)
            pooled_flat = pooled.cpu().numpy().flatten()
            
            train_reps.append(pooled_flat)
            train_labels.append(label)
    
    X_train = np.array(train_reps)
    y_train = np.array(train_labels)
    
    print(f"Training representations shape: {X_train.shape}")
    
    # Extract RAW representations from validation set
    print("Extracting validation representations...")
    val_reps = []
    val_labels_raw = []
    
    with torch.no_grad():
        for idx in tqdm(range(len(val_dataset)), desc=f"Val L{layer_num}"):
            sentence = val_dataset[idx]["sentence"]
            label = val_dataset[idx]["label"]
            
            tokens = model.to_tokens(sentence)
            _, cache = model.run_with_cache(tokens)
            
            layer_acts = cache[hook_name]
            pooled = layer_acts.mean(dim=1)
            pooled_flat = pooled.cpu().numpy().flatten()
            
            val_reps.append(pooled_flat)
            val_labels_raw.append(label)
    
    X_val = np.array(val_reps)
    y_val = np.array(val_labels_raw)
    
    print(f"Validation representations shape: {X_val.shape}")
    
    # Train classifier
    print("Training classifier...")
    clf = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')
    clf.fit(X_train, y_train)
    
    predictions = clf.predict(X_val)
    
    acc = accuracy_score(y_val, predictions)
    p, r, f1, _ = precision_recall_fscore_support(y_val, predictions, average='binary')
    cm = confusion_matrix(y_val, predictions)
    
    layer_performance[layer_num] = {
        'accuracy': acc,
        'precision': p,
        'recall': r,
        'f1_score': f1,
        'improvement': acc - baseline_acc,
        'confusion_matrix': cm
    }
    
    print(f"Layer {layer_num} Accuracy: {acc:.4f} ({acc*100:.2f}%)")
    print(f"Improvement over baseline: {(acc - baseline_acc)*100:+.2f}%")
    
    # ========================================================================
    # PART B: SAE Feature Analysis
    # ========================================================================
    print(f"\n--- Part B: SAE Feature Analysis ---")
    
    try:
        release = "gpt2-small-hook-z-kk"
        sae_id = f"blocks.{layer_num}.hook_z"
        
        try:
            sae = SAE.from_pretrained(release, sae_id)
        except:
            sae = SAE.from_pretrained(release, sae_id)[0]
        
        sae.to(device)
        sae.eval()
        
        print(f"Loaded SAE: {sae_id}")
        
    except Exception as e:
        print(f"Could not load SAE for layer {layer_num}: {e}")
        continue
    
    # Extract SAE features from validation set
    print("Extracting SAE features...")
    
    # Store all active features and their activation values
    pos_active_features = set()  # All unique features for positive
    neg_active_features = set()  # All unique features for negative
    
    pos_feature_activations = {}  # feature_idx -> list of activation values
    neg_feature_activations = {}
    
    pos_feature_counts = Counter()  # How many samples each feature appears in
    neg_feature_counts = Counter()
    
    total_pos = 0
    total_neg = 0
    
    with torch.no_grad():
        for idx in tqdm(range(len(val_dataset)), desc=f"SAE L{layer_num}"):
            sentence = val_dataset[idx]["sentence"]
            label = val_dataset[idx]["label"]
            
            tokens = model.to_tokens(sentence)
            _, cache = model.run_with_cache(tokens)
            
            hook_acts = cache[hook_name]
            sae_feature_acts = sae.encode(hook_acts)
            
            # Pool across sequence dimension
            pooled_features = sae_feature_acts.mean(dim=1)
            pooled_features = pooled_features.cpu().numpy().flatten()
            
            # Get active features (activation > 0)
            active_indices = np.where(pooled_features > 0)[0]
            active_values = pooled_features[active_indices]
            
            if label == 1:  # Positive
                total_pos += 1
                for feat_idx, act_val in zip(active_indices, active_values):
                    pos_active_features.add(feat_idx)
                    pos_feature_counts[feat_idx] += 1
                    if feat_idx not in pos_feature_activations:
                        pos_feature_activations[feat_idx] = []
                    pos_feature_activations[feat_idx].append(act_val)
            else:  # Negative
                total_neg += 1
                for feat_idx, act_val in zip(active_indices, active_values):
                    neg_active_features.add(feat_idx)
                    neg_feature_counts[feat_idx] += 1
                    if feat_idx not in neg_feature_activations:
                        neg_feature_activations[feat_idx] = []
                    neg_feature_activations[feat_idx].append(act_val)
    
    # Calculate statistics
    common_features = pos_active_features & neg_active_features
    pos_only_features = pos_active_features - neg_active_features
    neg_only_features = neg_active_features - pos_active_features
    
    # Calculate average activation for each feature
    pos_avg_activations = {f: np.mean(acts) for f, acts in pos_feature_activations.items()}
    neg_avg_activations = {f: np.mean(acts) for f, acts in neg_feature_activations.items()}
    
    # Get top 5 most activating features by average activation value
    top5_pos_by_activation = sorted(pos_avg_activations.items(), key=lambda x: x[1], reverse=True)[:5]
    top5_neg_by_activation = sorted(neg_avg_activations.items(), key=lambda x: x[1], reverse=True)[:5]
    
    # Get top 5 most frequent features
    top5_pos_by_frequency = pos_feature_counts.most_common(5)
    top5_neg_by_frequency = neg_feature_counts.most_common(5)
    
    # Store statistics
    sae_feature_stats[layer_num] = {
        'total_pos_features': len(pos_active_features),
        'total_neg_features': len(neg_active_features),
        'common_features': len(common_features),
        'pos_only_features': len(pos_only_features),
        'neg_only_features': len(neg_only_features),
        'top5_pos_by_activation': top5_pos_by_activation,
        'top5_neg_by_activation': top5_neg_by_activation,
        'top5_pos_by_frequency': top5_pos_by_frequency,
        'top5_neg_by_frequency': top5_neg_by_frequency,
        'total_pos_samples': total_pos,
        'total_neg_samples': total_neg,
        'pos_avg_activations': pos_avg_activations,
        'neg_avg_activations': neg_avg_activations,
        'pos_feature_counts': pos_feature_counts,
        'neg_feature_counts': neg_feature_counts,
        'common_features_set': common_features
    }
    
    # Print results
    print(f"\n=== SAE Feature Statistics for Layer {layer_num} ===")
    print(f"Total POSITIVE samples: {total_pos}")
    print(f"Total NEGATIVE samples: {total_neg}")
    print(f"")
    print(f"Total features activated for POSITIVE: {len(pos_active_features)}")
    print(f"Total features activated for NEGATIVE: {len(neg_active_features)}")
    print(f"COMMON features (both): {len(common_features)}")
    print(f"UNIQUE to POSITIVE only: {len(pos_only_features)}")
    print(f"UNIQUE to NEGATIVE only: {len(neg_only_features)}")
    print(f"")
    print(f"Top 5 Most Activating Features (POSITIVE) - by avg activation:")
    for rank, (feat_idx, avg_act) in enumerate(top5_pos_by_activation, 1):
        freq = pos_feature_counts[feat_idx]
        pct = freq / total_pos * 100
        status = "COMMON" if feat_idx in common_features else "UNIQUE"
        print(f"  {rank}. Feature {feat_idx}: avg_act={avg_act:.4f}, freq={freq} ({pct:.1f}%) | {status}")
    
    print(f"")
    print(f"Top 5 Most Activating Features (NEGATIVE) - by avg activation:")
    for rank, (feat_idx, avg_act) in enumerate(top5_neg_by_activation, 1):
        freq = neg_feature_counts[feat_idx]
        pct = freq / total_neg * 100
        status = "COMMON" if feat_idx in common_features else "UNIQUE"
        print(f"  {rank}. Feature {feat_idx}: avg_act={avg_act:.4f}, freq={freq} ({pct:.1f}%) | {status}")
    
    # Save detailed results for this layer
    with open(f'/kaggle/working/results/layer_{layer_num}_complete_analysis.txt', 'w') as f:
        f.write("="*70 + "\n")
        f.write(f"LAYER {layer_num} - COMPLETE ANALYSIS\n")
        f.write("="*70 + "\n\n")
        
        f.write("A. LAYER PERFORMANCE (Raw Representations)\n")
        f.write("-"*70 + "\n")
        f.write(f"Accuracy: {acc:.4f} ({acc*100:.2f}%)\n")
        f.write(f"Precision: {p:.4f}\n")
        f.write(f"Recall: {r:.4f}\n")
        f.write(f"F1-Score: {f1:.4f}\n")
        f.write(f"Baseline Accuracy: {baseline_acc:.4f}\n")
        f.write(f"Improvement over baseline: {(acc - baseline_acc)*100:+.2f}%\n\n")
        
        f.write("Confusion Matrix:\n")
        f.write("              Predicted\n")
        f.write("              Neg    Pos\n")
        f.write(f"Actual Neg  [{cm[0,0]:5d}  {cm[0,1]:5d}]\n")
        f.write(f"       Pos  [{cm[1,0]:5d}  {cm[1,1]:5d}]\n\n")
        
        f.write("B. SAE FEATURE COUNTS\n")
        f.write("-"*70 + "\n")
        f.write(f"Total POSITIVE samples: {total_pos}\n")
        f.write(f"Total NEGATIVE samples: {total_neg}\n\n")
        f.write(f"Total features activated for POSITIVE: {len(pos_active_features)}\n")
        f.write(f"Total features activated for NEGATIVE: {len(neg_active_features)}\n")
        f.write(f"COMMON features (activated for both): {len(common_features)}\n")
        f.write(f"UNIQUE to POSITIVE only: {len(pos_only_features)}\n")
        f.write(f"UNIQUE to NEGATIVE only: {len(neg_only_features)}\n\n")
        
        f.write("C. TOP 5 MOST ACTIVATING FEATURES (POSITIVE)\n")
        f.write("-"*70 + "\n")
        f.write("Ranked by average activation value:\n")
        for rank, (feat_idx, avg_act) in enumerate(top5_pos_by_activation, 1):
            freq = pos_feature_counts[feat_idx]
            pct = freq / total_pos * 100
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(f"{rank}. Feature {feat_idx}: avg_activation={avg_act:.4f}, "
                   f"frequency={freq}/{total_pos} ({pct:.1f}%) | {status}\n")
        
        f.write("\nD. TOP 5 MOST ACTIVATING FEATURES (NEGATIVE)\n")
        f.write("-"*70 + "\n")
        f.write("Ranked by average activation value:\n")
        for rank, (feat_idx, avg_act) in enumerate(top5_neg_by_activation, 1):
            freq = neg_feature_counts[feat_idx]
            pct = freq / total_neg * 100
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(f"{rank}. Feature {feat_idx}: avg_activation={avg_act:.4f}, "
                   f"frequency={freq}/{total_neg} ({pct:.1f}%) | {status}\n")
        
        f.write("\nE. TOP 5 MOST FREQUENT FEATURES (POSITIVE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, count) in enumerate(top5_pos_by_frequency, 1):
            pct = count / total_pos * 100
            avg_act = pos_avg_activations[feat_idx]
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(f"{rank}. Feature {feat_idx}: count={count} ({pct:.1f}%), "
                   f"avg_activation={avg_act:.4f} | {status}\n")
        
        f.write("\nF. TOP 5 MOST FREQUENT FEATURES (NEGATIVE)\n")
        f.write("-"*70 + "\n")
        for rank, (feat_idx, count) in enumerate(top5_neg_by_frequency, 1):
            pct = count / total_neg * 100
            avg_act = neg_avg_activations[feat_idx]
            status = "COMMON" if feat_idx in common_features else "UNIQUE"
            f.write(f"{rank}. Feature {feat_idx}: count={count} ({pct:.1f}%), "
                   f"avg_activation={avg_act:.4f} | {status}\n")
    
    print(f"✓ Layer {layer_num} complete analysis saved")

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "="*70)
print("FINAL SUMMARY")
print("="*70)

best_layer = max(layer_performance.items(), key=lambda x: x[1]['accuracy'])
worst_layer = min(layer_performance.items(), key=lambda x: x[1]['accuracy'])

# Print summary table
print(f"\n{'Layer':<6} {'Acc%':<8} {'Improv':<10} {'Pos Feat':<10} {'Neg Feat':<10} "
      f"{'Common':<10} {'Pos Only':<10} {'Neg Only':<10}")
print("-"*84)

for layer_num in sorted(layer_performance.keys()):
    perf = layer_performance[layer_num]
    stats = sae_feature_stats.get(layer_num, {})
    
    print(f"L{layer_num:<5} {perf['accuracy']*100:5.2f}%   "
          f"{perf['improvement']*100:+6.2f}%    "
          f"{stats.get('total_pos_features', 'N/A'):<10} "
          f"{stats.get('total_neg_features', 'N/A'):<10} "
          f"{stats.get('common_features', 'N/A'):<10} "
          f"{stats.get('pos_only_features', 'N/A'):<10} "
          f"{stats.get('neg_only_features', 'N/A'):<10}")

print(f"\n✓ Best layer: Layer {best_layer[0]} ({best_layer[1]['accuracy']*100:.2f}% accuracy)")
print(f"✓ Worst layer: Layer {worst_layer[0]} ({worst_layer[1]['accuracy']*100:.2f}% accuracy)")

# Save final summary
with open('/kaggle/working/results/final_summary.txt', 'w') as f:
    f.write("="*70 + "\n")
    f.write("FINAL SUMMARY - LAYER-WISE ANALYSIS\n")
    f.write("="*70 + "\n\n")
    
    f.write("1. BASELINE (Zero-Shot Prompting)\n")
    f.write("-"*70 + "\n")
    f.write(f"Accuracy: {baseline_acc*100:.2f}%\n")
    f.write(f"F1-Score: {baseline_f1:.4f}\n\n")
    
    f.write("2. LAYER-WISE PERFORMANCE & SAE FEATURE STATISTICS\n")
    f.write("-"*70 + "\n")
    f.write(f"{'Layer':<6} {'Acc%':<8} {'Improv':<10} {'Pos Feat':<10} {'Neg Feat':<10} "
           f"{'Common':<10} {'Pos Only':<10} {'Neg Only':<10}\n")
    f.write("-"*84 + "\n")
    
    for layer_num in sorted(layer_performance.keys()):
        perf = layer_performance[layer_num]
        stats = sae_feature_stats.get(layer_num, {})
        
        f.write(f"L{layer_num:<5} {perf['accuracy']*100:5.2f}%   "
               f"{perf['improvement']*100:+6.2f}%    "
               f"{stats.get('total_pos_features', 'N/A'):<10} "
               f"{stats.get('total_neg_features', 'N/A'):<10} "
               f"{stats.get('common_features', 'N/A'):<10} "
               f"{stats.get('pos_only_features', 'N/A'):<10} "
               f"{stats.get('neg_only_features', 'N/A'):<10}\n")
    
    f.write("\n3. TOP 5 MOST ACTIVATING FEATURES PER LAYER\n")
    f.write("-"*70 + "\n")
    
    for layer_num in sorted(sae_feature_stats.keys()):
        stats = sae_feature_stats[layer_num]
        f.write(f"\nLayer {layer_num}:\n")
        f.write(f"  POSITIVE (by activation): ")
        for feat_idx, avg_act in stats['top5_pos_by_activation']:
            f.write(f"F{feat_idx}({avg_act:.3f}) ")
        f.write(f"\n  NEGATIVE (by activation): ")
        for feat_idx, avg_act in stats['top5_neg_by_activation']:
            f.write(f"F{feat_idx}({avg_act:.3f}) ")
        f.write("\n")
    
    f.write("\n4. KEY FINDINGS\n")
    f.write("-"*70 + "\n")
    f.write(f"Best Performing Layer: Layer {best_layer[0]}\n")
    f.write(f"  Accuracy: {best_layer[1]['accuracy']*100:.2f}%\n")
    f.write(f"  Improvement over baseline: {best_layer[1]['improvement']*100:+.2f}%\n")
    f.write(f"  → This layer encodes the most sentiment information\n\n")
    
    f.write(f"Worst Performing Layer: Layer {worst_layer[0]}\n")
    f.write(f"  Accuracy: {worst_layer[1]['accuracy']*100:.2f}%\n\n")
    
    f.write("INTERPRETATION:\n")
    f.write("- Higher accuracy = more sentiment information linearly accessible in layer\n")
    f.write("- More unique features = better class separation in SAE space\n")
    f.write("- Fewer common features = more distinct representations per sentiment\n")

print("\n✓ All results saved to /kaggle/working/results/")
print("="*70)

