# -*- coding: utf-8 -*-
"""Qwen3-0.6B vs GPT2 Small.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jRhHy41g9-XYB8K3RgPhnFK6CmZEDYR7
"""

!pip install transformers datasets sentence-transformers torch sae-lens
!pip install sae-lens transformer_lens transformers datasets torch matplotlib scikit-learn
!pip install sentence-transformers scikit-learn pandas numpy tqdm
!pip install groq

"""
Feature Similarity Analysis - Top 10 Most Similar Features
===========================================================
Finds and reports the top 10 Qwen3 features most similar to GPT-2 features.

Requirements:
    pip install sentence-transformers scikit-learn pandas numpy tqdm
"""

import os
import re
import numpy as np
import pandas as pd
from typing import List, Dict
import warnings
warnings.filterwarnings('ignore')

print("\n" + "="*80)
print("TOP 10 SIMILAR FEATURES ANALYSIS - Qwen3-0.6B vs GPT-2 Small")
print("="*80 + "\n")

# Import dependencies
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    from tqdm import tqdm
except ImportError as e:
    print(f"✗ Missing dependency: {e}")
    print("Install: pip install sentence-transformers scikit-learn pandas numpy tqdm")
    exit(1)


# ============================================================================
# PARSING FUNCTION
# ============================================================================

def parse_interpretability_report(filename: str) -> List[Dict]:
    """Parse interpretability report to extract features."""
    print(f"Parsing {filename}...")

    with open(filename, 'r', encoding='utf-8') as f:
        content = f.read()

    features = []
    sections = content.split('======================================================================')

    for section in sections:
        if not section.strip() or 'SUMMARY' in section or 'REPORT FOR' in section:
            continue

        # Extract feature info
        feat_match = re.search(r'Feature:\s*Feature\s*(\d+)\s*\((\w+)\s+sentiment\)', section)
        if not feat_match:
            continue

        # Extract interpretation
        interp_match = re.search(r'Llama 3 Interpretation:\s*\n(.*?)\n\nEvaluation', section, re.DOTALL)
        if not interp_match:
            continue

        # Extract correlation score
        score_match = re.search(r'Overall.*?Correlation Score:\s*([-\d.]+)', section)
        if not score_match:
            continue

        features.append({
            'feature_id': int(feat_match.group(1)),
            'sentiment_type': feat_match.group(2),
            'interpretation': interp_match.group(1).strip(),
            'correlation_score': float(score_match.group(1))
        })

    print(f"✓ Found {len(features)} features")
    return features


# ============================================================================
# SIMILARITY COMPUTATION
# ============================================================================

def compute_similarity(text1: str, text2: str, model) -> float:
    """Compute cosine similarity between two texts."""
    emb1 = model.encode(text1, convert_to_tensor=False, show_progress_bar=False)
    emb2 = model.encode(text2, convert_to_tensor=False, show_progress_bar=False)

    emb1 = emb1.reshape(1, -1)
    emb2 = emb2.reshape(1, -1)

    return float(cosine_similarity(emb1, emb2)[0][0])


def find_best_matches(qwen_features, gpt2_features, model):
    """For each Qwen3 feature, find the most similar GPT-2 feature."""
    print(f"\nComputing similarities...")
    print(f"Total comparisons: {len(qwen_features)} × {len(gpt2_features)} = {len(qwen_features) * len(gpt2_features)}")

    results = []

    for qwen_feat in tqdm(qwen_features, desc="Analyzing Qwen3 features"):
        best_score = -1
        best_gpt2_feat = None

        # Compare against all GPT-2 features
        for gpt2_feat in gpt2_features:
            score = compute_similarity(
                qwen_feat['interpretation'],
                gpt2_feat['interpretation'],
                model
            )

            if score > best_score:
                best_score = score
                best_gpt2_feat = gpt2_feat

        results.append({
            'qwen3_feature_id': qwen_feat['feature_id'],
            'qwen3_sentiment': qwen_feat['sentiment_type'],
            'qwen3_interpretation': qwen_feat['interpretation'],
            'qwen3_correlation_score': qwen_feat['correlation_score'],
            'gpt2_feature_id': best_gpt2_feat['feature_id'],
            'gpt2_sentiment': best_gpt2_feat['sentiment_type'],
            'gpt2_interpretation': best_gpt2_feat['interpretation'],
            'gpt2_correlation_score': best_gpt2_feat['correlation_score'],
            'similarity_score': best_score
        })

    return pd.DataFrame(results)


# ============================================================================
# TOP 10 REPORT GENERATION
# ============================================================================

def save_top10_report(results_df, output_filename):
    """Save a detailed report of top 10 most similar feature pairs."""
    print(f"\nGenerating top 10 report: {output_filename}")

    # Get top 10 by similarity score
    top10 = results_df.nlargest(10, 'similarity_score')

    with open(output_filename, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("TOP 10 MOST SIMILAR FEATURES\n")
        f.write("Qwen3-0.6B SAE vs GPT-2 Small SAE\n")
        f.write("="*80 + "\n\n")

        f.write(f"Total Qwen3 features analyzed: {len(results_df)}\n")
        f.write(f"Total GPT-2 features available: {results_df['gpt2_feature_id'].nunique()}\n")
        f.write(f"Average similarity score (all): {results_df['similarity_score'].mean():.4f}\n")
        f.write(f"Top 10 average similarity: {top10['similarity_score'].mean():.4f}\n\n")

        # Summary table
        f.write("="*80 + "\n")
        f.write("SUMMARY TABLE - TOP 10 PAIRS\n")
        f.write("="*80 + "\n\n")

        f.write(f"{'Rank':<6} {'Qwen3 F':<10} {'GPT-2 F':<10} {'Similarity':<12} {'Qwen3 Corr':<13} {'GPT-2 Corr':<13}\n")
        f.write("-"*80 + "\n")

        for rank, (idx, row) in enumerate(top10.iterrows(), 1):
            f.write(f"{rank:<6} ")
            f.write(f"{row['qwen3_feature_id']:<10} ")
            f.write(f"{row['gpt2_feature_id']:<10} ")
            f.write(f"{row['similarity_score']:.4f}      ")
            f.write(f"{row['qwen3_correlation_score']:>6.4f}       ")
            f.write(f"{row['gpt2_correlation_score']:>6.4f}\n")

        f.write("\n\n")

        # Detailed analysis for each pair
        f.write("="*80 + "\n")
        f.write("DETAILED ANALYSIS - TOP 10 PAIRS\n")
        f.write("="*80 + "\n\n")

        for rank, (idx, row) in enumerate(top10.iterrows(), 1):
            f.write("="*80 + "\n")
            f.write(f"RANK {rank}\n")
            f.write("="*80 + "\n\n")

            # Qwen3 Feature
            f.write(f"QWEN3 FEATURE {row['qwen3_feature_id']}\n")
            f.write("-"*80 + "\n")
            f.write(f"Sentiment: {row['qwen3_sentiment'].upper()}\n")
            f.write(f"Interpretability Score: {row['qwen3_correlation_score']:.4f}\n\n")
            f.write("INTERPRETATION:\n")
            f.write(row['qwen3_interpretation'])
            f.write("\n\n")

            # GPT-2 Feature
            f.write(f"GPT-2 FEATURE {row['gpt2_feature_id']}\n")
            f.write("-"*80 + "\n")
            f.write(f"Sentiment: {row['gpt2_sentiment'].upper()}\n")
            f.write(f"Interpretability Score: {row['gpt2_correlation_score']:.4f}\n\n")
            f.write("INTERPRETATION:\n")
            f.write(row['gpt2_interpretation'])
            f.write("\n\n")

            # Similarity metrics
            f.write("SIMILARITY ANALYSIS\n")
            f.write("-"*80 + "\n")
            f.write(f"Semantic Similarity Score: {row['similarity_score']:.4f}\n")
            f.write(f"Sentiment Match: {'YES' if row['qwen3_sentiment'] == row['gpt2_sentiment'] else 'NO'}\n")
            f.write(f"Qwen3 Interpretability: {row['qwen3_correlation_score']:.4f}\n")
            f.write(f"GPT-2 Interpretability: {row['gpt2_correlation_score']:.4f}\n")
            f.write("\n\n")

    print(f"✓ Report saved successfully")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution function."""

    # Configuration
    QWEN_REPORT = '/kaggle/input/iscore/all_interpretibilityscore_2048.txt'
    GPT2_REPORT = '/kaggle/input/iscore/all_interpretabilityscore_gpt2.txt'
    OUTPUT_TXT = '/kaggle/working/top10_similar_features.txt'
    OUTPUT_CSV = '/kaggle/working/top10_similar_features.csv'

    # Check input files
    if not os.path.exists(QWEN_REPORT):
        print(f"✗ Error: {QWEN_REPORT} not found!")
        return
    if not os.path.exists(GPT2_REPORT):
        print(f"✗ Error: {GPT2_REPORT} not found!")
        return

    print("Input files found:")
    print(f"  ✓ {QWEN_REPORT}")
    print(f"  ✓ {GPT2_REPORT}\n")

    # Parse reports
    print("Step 1: Parsing reports")
    print("-"*80)
    qwen_features = parse_interpretability_report(QWEN_REPORT)
    gpt2_features = parse_interpretability_report(GPT2_REPORT)

    if len(qwen_features) == 0 or len(gpt2_features) == 0:
        print("✗ Error: No features found!")
        return

    # Load model
    print("\nStep 2: Loading sentence transformer model")
    print("-"*80)
    print("Model: all-MiniLM-L6-v2")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    print("✓ Model loaded")

    # Compute similarities
    print("\nStep 3: Computing similarities")
    print("-"*80)
    results_df = find_best_matches(qwen_features, gpt2_features, model)

    # Save top 10 report
    print("\nStep 4: Saving results")
    print("-"*80)

    save_top10_report(results_df, OUTPUT_TXT)

    # Also save top 10 CSV
    top10_df = results_df.nlargest(10, 'similarity_score')
    top10_df.to_csv(OUTPUT_CSV, index=False)
    print(f"✓ CSV saved: {OUTPUT_CSV}")

    # Display summary
    print("\n" + "="*80)
    print("ANALYSIS COMPLETE!")
    print("="*80)

    print("\nTop 10 Most Similar Feature Pairs:")
    print(f"{'Rank':<6} {'Qwen3':<8} {'GPT-2':<8} {'Similarity':<12} {'Sentiments':<20}")
    print("-"*80)

    for rank, (idx, row) in enumerate(top10_df.iterrows(), 1):
        sentiments = f"{row['qwen3_sentiment'][:3]}-{row['gpt2_sentiment'][:3]}"
        print(f"{rank:<6} F{row['qwen3_feature_id']:<7} F{row['gpt2_feature_id']:<7} "
              f"{row['similarity_score']:.4f}      {sentiments}")

    print(f"\nOutput files:")
    print(f"  • {OUTPUT_TXT} (detailed report)")
    print(f"  • {OUTPUT_CSV} (top 10 data)")
    print()


if __name__ == "__main__":
    main()

